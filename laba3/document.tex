\documentclass[a4paper,14pt]{extarticle}
\usepackage[T1, T2A]{fontenc}
\usepackage{textcomp}

\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{xcolor}  % Для цветов в коде

\lstset{
	language=Python,
	basicstyle=\ttfamily\footnotesize,
	numbers=left,
	numberstyle=\tiny\color{gray},
	stepnumber=1,
	numbersep=5pt,
	backgroundcolor=\color{white},
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	frame=single,
	rulecolor=\color{black},
	tabsize=2,
	captionpos=b,
	breaklines=true,
	breakatwhitespace=false,
	escapeinside={\%*}{*)},
	keywordstyle=\color{blue},
	commentstyle=\color{green},
	stringstyle=\color{red},
	literate={а}{{\selectfont\char224}}1
	{б}{{\selectfont\char225}}1
	{в}{{\selectfont\char226}}1
	{г}{{\selectfont\char227}}1
	{д}{{\selectfont\char228}}1
	{е}{{\selectfont\char229}}1
	{ё}{{\selectfont\char184}}1
	{ж}{{\selectfont\char230}}1
	{з}{{\selectfont\char231}}1
	{и}{{\selectfont\char232}}1
	{й}{{\selectfont\char233}}1
	{к}{{\selectfont\char234}}1
	{л}{{\selectfont\char235}}1
	{м}{{\selectfont\char236}}1
	{н}{{\selectfont\char237}}1
	{о}{{\selectfont\char238}}1
	{п}{{\selectfont\char239}}1
	{р}{{\selectfont\char240}}1
	{с}{{\selectfont\char241}}1
	{т}{{\selectfont\char242}}1
	{у}{{\selectfont\char243}}1
	{ф}{{\selectfont\char244}}1
	{х}{{\selectfont\char245}}1
	{ц}{{\selectfont\char246}}1
	{ч}{{\selectfont\char247}}1
	{ш}{{\selectfont\char248}}1
	{щ}{{\selectfont\char249}}1
	{ъ}{{\selectfont\char250}}1
	{ы}{{\selectfont\char251}}1
	{ь}{{\selectfont\char252}}1
	{э}{{\selectfont\char253}}1
	{ю}{{\selectfont\char254}}1
	{я}{{\selectfont\char255}}1
	{А}{{\selectfont\char192}}1
	{Б}{{\selectfont\char193}}1
	{В}{{\selectfont\char194}}1
	{Г}{{\selectfont\char195}}1
	{Д}{{\selectfont\char196}}1
	{Е}{{\selectfont\char197}}1
	{Ё}{{\selectfont\char168}}1
	{Ж}{{\selectfont\char198}}1
	{З}{{\selectfont\char199}}1
	{И}{{\selectfont\char200}}1
	{Й}{{\selectfont\char201}}1
	{К}{{\selectfont\char202}}1
	{Л}{{\selectfont\char203}}1
	{М}{{\selectfont\char204}}1
	{Н}{{\selectfont\char205}}1
	{О}{{\selectfont\char206}}1
	{П}{{\selectfont\char207}}1
	{Р}{{\selectfont\char208}}1
	{С}{{\selectfont\char209}}1
	{Т}{{\selectfont\char210}}1
	{У}{{\selectfont\char211}}1
	{Ф}{{\selectfont\char212}}1
	{Х}{{\selectfont\char213}}1
	{Ц}{{\selectfont\char214}}1
	{Ч}{{\selectfont\char215}}1
	{Ш}{{\selectfont\char216}}1
	{Щ}{{\selectfont\char217}}1
	{Ъ}{{\selectfont\char218}}1
	{Ы}{{\selectfont\char219}}1
	{Ь}{{\selectfont\char220}}1
	{Э}{{\selectfont\char221}}1
	{Ю}{{\selectfont\char222}}1
	{Я}{{\selectfont\char223}}1
}

\usepackage[normalem]{ulem} 
\usepackage{tabularray}
\usepackage{graphicx}
\usepackage{diagbox} 
\usepackage{multirow}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{ragged2e}
\usepackage[english, russian]{babel}
\usepackage{setspace}
\setlength{\parskip}{0.5cm}
\linespread{1.5}
\setlength{\parindent}{0.5cm}
\usepackage[a4paper, papersize={210mm, 297mm}, text={210mm, 297mm},
left=2cm, top=2cm, right=1.5cm, bottom=2cm]{geometry}
\begin{document} 
	\begin{center}
		\normalsize{МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ
			РОССИЙСКОЙ ФЕДЕРАЦИИ}\\
		\normalsize{ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ
			УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ\\
			«ВЯТСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ»}\\ 
		\normalsize{Институт математики и информационных систем}\\
		\normalsize{Факультет автоматики и вычислительной техники}\\
		\normalsize{Кафедра электронных вычислительных машин}\\
	\end{center}
	
	\begin{flushright}
		\small{Дата сдачи на проверку:}\\
		\small{«}\underline{\hspace{0.5cm}}\small{»}\underline{\hspace{2cm}} \small{2025 г.}\\
		\small{Проверено:} \rule[0ex]{2.3cm}{0pt}\\
		\small{«}\underline{\hspace{0.5cm}}\small{»}\underline{\hspace{2cm}}\small{2025 г.} 
	\end{flushright}
	\begin{center}
		\normalsize{Вариант 18}\\
		\normalsize{Отчет по лабораторной работе № 3 }\\ по дисциплине \\ 
		\normalsize{«Вычислительная математика»}\\
		
		
	\end{center}
	
	
	\begin{flushleft}
		\hfill \break
		\hfill \break
		\normalsize{ Разработал студент гр. ИВТб 2302-05-00}\rule[0ex]{0.1cm}{0pt} \underline{\hspace{4cm}}  \normalsize{/Соловьев А.С./} \\
		\rule[0ex]{9.6cm}{0pt} \tiny{(Подпись)}\\
		\normalsize{ Проверил заведующий кафедры ЭВМ}  \rule[0ex]{0.1cm}{0pt} \underline{\hspace{4cm}} \normalsize{/Старостин П.А./} \\ 
		\rule[0ex]{9.6cm}{0pt} \tiny{(Подпись)}\\
		\normalsize{ Работа защищена} \rule[0ex]{8.5cm}{0pt} \small{«}\underline{\hspace{0.5cm}}\small{»}\underline{\hspace{2.6cm}}\small{2025 г.}
		\hfill \break
		\hfill \break
	\end{flushleft}
	\begin{center} Киров 2025 \end{center}
	\thispagestyle{empty} % выключаем отображение номера для этой страницы
	
	\newpage
	
	\section{Задание}
	\begin{enumerate}
		\item По таблице с неравноотстоящими значениями аргумента выполнить интерполяцию, используя формулу Лангранджа. Точность $E<=10^{-6}$
		
		
		Для X=0,692\\
		
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|}
			\hline
			\( x \) & \( f(x) \) \\
			\hline
			0.62 & 0.537944 \\
			0.67 & 0.511709 \\
			0.74 & 0.477114 \\
			0.80 & 0.449329 \\
			0.87 & 0.418952 \\
			0.96 & 0.382893 \\
			0.99 & 0.371577 \\
			\hline
		\end{tabular}
		\caption{Таблица значений функции}
		\label{tab:values}
	\end{table}
	
	\item По таблице с равностоящими значениями аргумента вычислить значения функции для заданных значенй аргументов, используя первую и вторую интерполяционные формулы Ньютона. Точность E<=0.000001.\\
	$x_1 = 1.4161$\\
	$x_2 = 1.4625$\\
	$x_3 = 1.4135$\\
	$x_4 = 1.4700$\\
	\begin{table}[H]
		\centering
		\begin{tabular}{|c|c|}
			\hline
			\( x \) & \( f(x) \) \\
			\hline
			0.01 & 0.991824 \\
			0.06 & 0.951935 \\
			0.11 & 0.913650 \\
			0.16 & 0.876905 \\
			0.21 & 0.841638 \\
			0.26 & 0.807789 \\
			0.31 & 0.775301 \\
			0.36 & 0.744120 \\
			0.41 & 0.714198 \\
			0.46 & 0.685470 \\
			0.51 & 0.657902 \\
			0.56 & 0.631442 \\
			\hline
		\end{tabular}
		\caption{Таблица значений функции}
	\end{table}
	
	
	
	\item  По заданным эксперементальным точкам выбрать вид эмпиреической зависимости и выполнить среднеквадратичное приближение функции,
	\[
	\begin{array}{|c|c|}
		\hline
		x_i & y_i \\ \hline
		0.1 & 1.91 \\ 
		0.2 & 3.03 \\
		0.3 & 3.98 \\ 
		0.4 & 4.82 \\
		0.5 & 5.59 \\
		0.6 & 6.31 \\
		0.7 & 7.00 \\
		0.8 & 7.65 \\
		0.9 & 8.27 \\ 
		1.0 & 8.88 \\ \hline
	\end{array}
	\]
	
	\end{enumerate}
	
	
	\section{Теорическая часть.Описание методов решения уравнений}
\subsection*{Суть метода Лагранжа}

Метод интерполяции полиномом Лагранжа позволяет найти многочлен степени \( n \), который проходит через заданные точки \( (x_0, y_0), (x_1, y_1), \dots, (x_n, y_n) \).

\subsection*{Формула интерполяционного полинома}
Интерполяционный полином Лагранжа имеет вид:

\[
L_n(x) = \sum_{i=0}^{n} y_i \cdot l_i(x),
\]

где базисные полиномы \( l_i(x) \) определяются следующим образом:

\[
l_i(x) = \prod_{\substack{j=0 \\ j\neq i}}^{n} \frac{x - x_j}{x_i - x_j}.
\]

Каждый базисный полином \( l_i(x) \) принимает значение 1 в точке \( x_i \) и 0 во всех остальных узлах \( x_j \) (\( j \neq i \)).

\subsection*{Линейная интерполяция (\( L_1 \))}
Используется два узла \((x_0, y_0)\) и \((x_1, y_1)\):
\[
L_1(x) = y_0 \cdot \frac{x - x_1}{x_0 - x_1} + y_1 \cdot \frac{x - x_0}{x_1 - x_0}
\]

\subsection*{Квадратичная интерполяция (\( L_2 \))}
Добавляется третий узел \((x_2, y_2)\):
\[
L_2(x) = L_1(x) + y_2 \cdot \frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)}
\]
\\
Для полинома $L_n$ составляется аналогичный полином как для $L_1$ и $L_2$ через рекурсивный вызов.\\
\subsection*{Алгоритм вычисления}
1. Заданы \( n+1 \) узлов интерполяции \( (x_i, y_i) \).
2. Для каждого \( x_i \) вычисляются базисные полиномы \( l_i(x) \).
3. Итоговый полином получается как сумма произведений значений функции \( y_i \) на соответствующие базисные полиномы.
4. При необходимости можно вычислить значение \( L_n(x) \) в любой точке \( x \).

\subsection{Метод интерполяции Ньютона}
Интерполяционные формулы Ньютона применяются для построения интерполяционного многочлена $P_n(x)$ по заданным значениям функции в равноотстоящих узлах.

\subsection{Первая интерполяционная формула Ньютона}
Используется для интерполяции в начале отрезка ($x$ близко к $x_0$):

\begin{equation}
	P_n(x) = f(x_0) + \sum_{k=1}^{n} \Delta^k f(x_0) \cdot \frac{(x-x_0)(x-x_1)\cdots(x-x_{k-1})}{k!h^k}
\end{equation}

\subsubsection{Конечные разности и шаг интерполяции}
\begin{itemize}
	\item \textbf{Шаг $h$} - расстояние между соседними узлами: $h = x_{i+1} - x_i$ (для равномерной сетки)
	
	\item \textbf{Конечные разности} вычисляются рекуррентно:
	\\\begin{align*}
		\Delta^1 f(x_i) &= f(x_{i+1}) - f(x_i) \quad \text{(первая разность)} \\
		\Delta^2 f(x_i) &= \Delta^1 f(x_{i+1}) - \Delta^1 f(x_i) \quad \text{(вторая разность)} \\
		&\vdots \\
		\Delta^k f(x_i) &= \Delta^{k-1} f(x_{i+1}) - \Delta^{k-1} f(x_i)
	\end{align*}
	
	\item Разности нулевого порядка: $\Delta^0 f(x_i) = f(x_i)$
\end{itemize}

\subsection{Вторая интерполяционная формула Ньютона}
Применяется для интерполяции в конце отрезка ($x$ близко к $x_n$):

\begin{equation}
	P_n(x) = f(x_n) + \sum_{k=1}^{n} \nabla^k f(x_n) \cdot \frac{(x-x_n)(x-x_{n-1})\cdots(x-x_{n-k+1})}{k!h^k}
\end{equation}

\subsubsection{Обратные разности}
\begin{itemize}
	\item Вычисляются через прямые разности:
	\[ \nabla^k f(x_n) = \Delta^k f(x_{n-k}) \]
	
	\item Или рекуррентно:
	\begin{align*}
		\nabla^1 f(x_i) &= f(x_i) - f(x_{i-1}) \\
		\nabla^k f(x_i) &= \nabla^{k-1} f(x_i) - \nabla^{k-1} f(x_{i-1})
	\end{align*}
\end{itemize}

\subsection{Особенности применения}
\begin{itemize}
	\item Первая формула использует разности "вперёд" ($\Delta$) от $x_0$
	\item Вторая формула использует разности "назад" ($\nabla$) от $x_n$
	\item Обе формулы требуют равномерной сетки (постоянного $h$)
	\item Для расчёта разностей составляется таблица конечных разностей
\end{itemize}
\subsection{Разделенные разности}
Разделенные разности определяются рекурсивно:
\begin{equation}
	f[x_i] = f(x_i),
\end{equation}
\begin{equation}
	f[x_i, x_{i+1}] = \frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i},
\end{equation}
\begin{equation}
	f[x_i, x_{i+1}, x_{i+2}] = \frac{f[x_{i+1}, x_{i+2}] - f[x_i, x_{i+1}]}{x_{i+2} - x_i},
\end{equation}
и так далее.

\section{Оценка погрешности}
Ошибка интерполяции определяется формулой:
\begin{equation}
	R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{i=0}^{n} (x - x_i), \quad \xi \in [x_0, x_n].
\end{equation}
Здесь $f^{(n+1)}(\xi)$ — производная порядка $n+1$ в некоторой точке $\xi$.

\section{Выбор вида эмпирической зависимости}
Перед применением МНК необходимо выбрать тип функции \( y = f(x) \), которая наилучшим образом описывает экспериментальные данные. Для этого можно использовать следующие подходы:

\subsection{Анализ средних значений}
Вычисляем средние арифметические, геометрические и гармонические для крайних точек данных:
\[
x_{\text{ср}} = \frac{x_1 + x_n}{2}, \quad y_{\text{ср}} = \frac{y_1 + y_n}{2},
\]
\[
x_{\text{геом}} = \sqrt{x_1 \cdot x_n}, \quad y_{\text{геом}} = \sqrt{y_1 \cdot y_n},
\]
\[
x_{\text{гарм}} = \frac{2x_1 x_n}{x_1 + x_n}, \quad y_{\text{гарм}} = \frac{2y_1 y_n}{y_1 + y_n}.
\]

\subsection{Определение минимальной ошибки}
Для каждой из средних точек \((x_{\text{ср}}, y_{\text{ср}})\), \((x_{\text{геом}}, y_{\text{геом}})\), \((x_{\text{гарм}}, y_{\text{гарм}})\) находим ближайшую экспериментальную точку и вычисляем ошибки:
\[
\text{Ошибка} = \sqrt{(x_i - x_{\text{ср}})^2 + (y_i - y_{\text{ср}})^2}.
\]
Минимальная ошибка указывает на наиболее подходящий тип зависимости (линейная, степенная, логарифмическая и т.д.).

\section{Метод наименьших квадратов для линейной зависимости}
Если анализ показывает, что линейная зависимость \( y = ax + b \) наиболее адекватна, параметры \(a\) и \(b\) находятся из условия минимизации суммы квадратов отклонений:
\[
S(a, b) = \sum_{i=1}^n (y_i - (a x_i + b))^2 \to \min.
\]

\subsection{Нормальные уравнения}
Частные производные \( \frac{\partial S}{\partial a} \) и \( \frac{\partial S}{\partial b} \) приводят к системе:
\[
\begin{cases}
	a \sum x_i^2 + b \sum x_i = \sum x_i y_i, \\
	a \sum x_i + b n = \sum y_i.
\end{cases}
\]

\subsection{Решение системы}
Коэффициенты вычисляются по формулам:
\[
a = \frac{n \sum x_i y_i - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i)^2}, \quad
b = \frac{\sum y_i - a \sum x_i}{n}.
\]

\section{Оценка точности аппроксимации}
Среднеквадратичное отклонение:
\[
\sigma = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - (a x_i + b))^2}.
\]



	\section{Практическая часть}
	
	\subsection*{Исходные данные}
	Заданы узлы интерполяции:
	
	\[
	\begin{array}{c|c}
		x & f(x) \\
		\hline
		0.62 & 0.537944 \\
		0.67 & 0.511709 \\
		0.74 & 0.477114 \\
		0.80 & 0.449329 \\
		0.87 & 0.418952 \\
		0.96 & 0.382893 \\
		0.99 & 0.371577 \\
	\end{array}
	\]
	
	Требуется найти значение функции в точке \( x = 0.692 \) с использованием полинома Лагранжа.
	
	\subsection*{Алгоритм решения}
	
	Метод Лагранжа заключается в представлении интерполяционного многочлена в виде:
	
	
	\[
	L_n(x) = \sum_{i=0}^{n} y_i \cdot l_i(x),
	\]
	
	где базисные полиномы \( l_i(x) \) определяются по формуле:
	
	\[
	l_i(x) = \prod_{\substack{j=0 \\ j\neq i}}^{n} \frac{x - x_j}{x_i - x_j}.
	\]
	
	\textbf{Алгоритм решения:}
	\begin{enumerate}
		\item Заданы массивы значений \( x \) и \( y \).
		\item Для каждого узла вычисляется базисный полином \( l_i(x) \).
		\item Итоговое значение функции в точке \( x = 0.692 \) находится по формуле Лагранжа.
		\item Строится график интерполяционного многочлена и отмечаются исходные точки.
	\end{enumerate}
		\begin{figure}[H] 
		\center
		\includegraphics [width=0.5\linewidth]{Задание1График.png}
		\caption{Метод Лангранжа} 
	\end{figure} 
	

\small 
\[
\ell_0(x) = \frac{(x - x_1)(x - x_2)(x - x_3)(x - x_4)(x - x_5)(x - x_6)}{(x_0 - x_1)(x_0 - x_2)(x_0 - x_3)(x_0 - x_4)(x_0 - x_5)(x_0 - x_6)}
\]

\[
\ell_1(x) = \frac{(x - x_0)(x - x_2)(x - x_3)(x - x_4)(x - x_5)(x - x_6)}{(x_1 - x_0)(x_1 - x_2)(x_1 - x_3)(x_1 - x_4)(x_1 - x_5)(x_1 - x_6)}
\]

\[
\ell_2(x) = \frac{(x - x_0)(x - x_1)(x - x_3)(x - x_4)(x - x_5)(x - x_6)}{(x_2 - x_0)(x_2 - x_1)(x_2 - x_3)(x_2 - x_4)(x_2 - x_5)(x_2 - x_6)}
\]

\[
\ell_3(x) = \frac{(x - x_0)(x - x_1)(x - x_2)(x - x_4)(x - x_5)(x - x_6)}{(x_3 - x_0)(x_3 - x_1)(x_3 - x_2)(x_3 - x_4)(x_3 - x_5)(x_3 - x_6)}
\]

\[
\ell_4(x) = \frac{(x - x_0)(x - x_1)(x - x_2)(x - x_3)(x - x_5)(x - x_6)}{(x_4 - x_0)(x_4 - x_1)(x_4 - x_2)(x_4 - x_3)(x_4 - x_5)(x_4 - x_6)}
\]

\[
\ell_5(x) = \frac{(x - x_0)(x - x_1)(x - x_2)(x - x_3)(x - x_4)(x - x_6)}{(x_5 - x_0)(x_5 - x_1)(x_5 - x_2)(x_5 - x_3)(x_5 - x_4)(x_5 - x_6)}
\]

\[
\ell_6(x) = \frac{(x - x_0)(x - x_1)(x - x_2)(x - x_3)(x - x_4)(x - x_5)}{(x_6 - x_0)(x_6 - x_1)(x_6 - x_2)(x_6 - x_3)(x_6 - x_4)(x_6 - x_5)}
\]

Найдем все $\ell(x)$
\[
\ell_0(0.692) = \frac{(0.692 - 0.67)(0.692 - 0.74)(0.692 - 0.80)(0.692 - 0.87)(0.692 - 0.96)(0.692 - 0.99)}{(0.62 - 0.67)(0.62 - 0.74)(0.62 - 0.80)(0.62 - 0.87)(0.62 - 0.96)(0.62 - 0.99)}
\]\\$\approxx -0.0477325$

\[
\ell_1(0.692) = \frac{(0.692 - 0.62)(0.692 - 0.74)(0.692 - 0.80)(0.692 - 0.87)(0.692 - 0.96)(0.692 - 0.99)}{(0.67 - 0.62)(0.67 - 0.74)(0.67 - 0.80)(0.67 - 0.87)(0.67 - 0.96)(0.67 - 0.99)}
\]\\$\approx  0.628318$

\[
\ell_2(0.692) = \frac{(0.692 - 0.62)(0.692 - 0.67)(0.692 - 0.80)(0.692 - 0.87)(0.692 - 0.96)(0.692 - 0.99)}{(0.74 - 0.62)(0.74 - 0.67)(0.74 - 0.80)(0.74 - 0.87)(0.74 - 0.96)(0.74 - 0.99)}
\]\\$\approx 0.674860$

\[
\ell_3(0.692) = \frac{(0.692 - 0.62)(0.692 - 0.67)(0.692 - 0.74)(0.692 - 0.87)(0.692 - 0.96)(0.692 - 0.99)}{(0.80 - 0.62)(0.80 - 0.67)(0.80 - 0.74)(0.80 - 0.87)(0.80 - 0.96)(0.80 - 0.99)}
\]\\$\approx -0.361767$

\[
\ell_4(0.692) = \frac{(0.692 - 0.62)(0.692 - 0.67)(0.692 - 0.74)(0.692 - 0.80)(0.692 - 0.96)(0.692 - 0.99)}{(0.87 - 0.62)(0.87 - 0.67)(0.87 - 0.74)(0.87 - 0.80)(0.87 - 0.96)(0.87 - 0.99)}
\]\\$\approx 0.133455$

\[
\ell_5(0.692) = \frac{(0.692 - 0.62)(0.692 - 0.67)(0.692 - 0.74)(0.692 - 0.80)(0.692 - 0.87)(0.692 - 0.99)}{(0.96 - 0.62)(0.96 - 0.67)(0.96 - 0.74)(0.96 - 0.80)(0.96 - 0.87)(0.96 - 0.99)}
\]\\$\approx -0.046481$

\[
\ell_6(0.692) = \frac{(0.692 - 0.62)(0.692 - 0.67)(0.692 - 0.74)(0.692 - 0.80)(0.692 - 0.87)(0.692 - 0.96)}{(0.99 - 0.62)(0.99 - 0.67)(0.99 - 0.74)(0.99 - 0.80)(0.99 - 0.87)(0.99 - 0.96)}  
\]\\$\approx 0.019348$


Подставим всё в многочлен:

\[
\begin{aligned}
	L_6(x) =\ & 0.537944 \cdot \ell_0(x) + 0.511709 \cdot \ell_1(x) + 0.477114 \cdot \ell_2(x) + \]\[
	& 0.449329 \cdot \ell_3(x) + 0.418952 \cdot \ell_4(x) + 0.382893 \cdot \ell_5(x) + 0.371577 \cdot \ell_6(x)
\end{aligned}
\]
\normalsize	
	Таким образом $L(0.692) = 0.500574 \pm 0.00001$. \\Сделаем проверку решения.
		\begin{figure}[H] 
		\center
		\includegraphics [width=0.5\linewidth]{Проверка.png}
		\caption{Проверка решения} 
	\end{figure} 
	После проверки понятно, что программа работает верно и верный рассчеты.
	
	\subsection*{Реализация на Python}
		\lstinputlisting[language=Python, caption={Python код программы}]{Lagrandge.py}
		
\subsection{Метод Ньютона с вычислением шага и конечных разностей}

Рассмотрим таблицу значений функции с равномерным шагом:

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\( x \) & \( f(x) \) \\
		\hline
		0.01 & 0.991824 \\
		0.06 & 0.951935 \\
		0.11 & 0.913650 \\
		0.16 & 0.876905 \\
		0.21 & 0.841638 \\
		0.26 & 0.807789 \\
		0.31 & 0.775301 \\
		0.36 & 0.744120 \\
		0.41 & 0.714198 \\
		0.46 & 0.685470 \\
		0.51 & 0.657902 \\
		0.56 & 0.631442 \\
		\hline
	\end{tabular}
	\caption{Таблица значений функции}
\end{table}

\subsubsection{Вычисление шага \( h \)}
Для данной таблицы шаг вычисляется как разность между соседними узлами:
\[
h = x_{i+1} - x_i = 0.06 - 0.01 = 0.05
\]
Все последующие разности между узлами одинаковы и равны \( h = 0.05 \), что подтверждает равномерность сетки.

\subsubsection{Построение таблицы конечных разностей \( \Delta^k \)}

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\( x_i \) & \( f(x_i) \) & \( \Delta^1 \) & \( \Delta^2 \) & \( \Delta^3 \) & \( \Delta^4 \) \\
		\hline
		0.01 & 0.991824 & -0.039889 & 0.001604 & -0.000071 & 0.000004 \\
		0.06 & 0.951935 & -0.038285 & 0.001533 & -0.000067 & 0.000004 \\
		0.11 & 0.913650 & -0.036752 & 0.001466 & -0.000063 &  \\
		0.16 & 0.876905 & -0.035286 & 0.001403 &  &  \\
		0.21 & 0.841638 & -0.033883 &  &  &  \\
		0.26 & 0.807789 &  &  &  &  \\
		\hline
	\end{tabular}
	\caption{Таблица конечных разностей (фрагмент)}
\end{table}

\paragraph{Пример вычисления разностей:}
\begin{align*}
	\Delta^1 f(x_0) &= f(x_1) - f(x_0) = 0.951935 - 0.991824 = -0.039889 \\
	\Delta^1 f(x_1) &= f(x_2) - f(x_1) = 0.913650 - 0.951935 = -0.038285 \\
	\Delta^2 f(x_0) &= \Delta^1 f(x_1) - \Delta^1 f(x_0) = (-0.038285) - (-0.039889) = 0.001604 \\
	\Delta^3 f(x_0) &= \Delta^2 f(x_1) - \Delta^2 f(x_0) = 0.001533 - 0.001604 = -0.000071
\end{align*}

\subsubsection{Применение первой формулы Ньютона}
Для точки \( x = 0.1243 \) (близко к началу таблицы):
\[
t = \frac{x - x_0}{h} = \frac{0.1243 - 0.01}{0.05} = 2.286
\]
\[
P_3(x) = 0.991824 + 2.286 \cdot (-0.039889) + \frac{2.286 \cdot 1.286}{2} \cdot 0.001604 + \cdots
\]

\subsubsection{Применение второй формулы Ньютона}
Для точки \( x = 0.492 \) (близко к концу таблицы) используем обратные разности \( \nabla^k \), которые совпадают с \( \Delta^k \) для соответствующих узлов.

\subsubsection{Анализ погрешности}
Погрешность оценивается через следующее слагаемое в ряду:
\[
R_n \approx \Delta^{n+1} f(x_0) \cdot \frac{t(t-1)\cdots(t-n)}{(n+1)!}
\]
Для \( x = 0.492 \) при \( n = 3 \):
\[
R_3 \approx 0.000004 \cdot \frac{t(t-1)(t-2)(t-3)}{24} \approx 8 \times 10^{-6}
\]

\begin{table}[h]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\( x \) & Интерполяция вперед & Интерполяция назад \\
		\hline
		0.1243 & 0.902986 & $-$\\
		0.492 & $-$& 0.66769 \\
		0.0024 &0.99805 & $-$\\
		0.66 & $-$& 0.55791\\
		\hline
	\end{tabular}
	\caption{Сравнение результатов}
\end{table}

		\begin{figure}[H] 
		\center
		\includegraphics [width=0.5\linewidth]{Задание2График.png}
		\caption{Графическое представление интерполяции}
	\end{figure} 
	Резулультаты работы формул для значений в точказ 	
		\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\textwidth]{ПроверкаЗадания2Формула1.png}
		\caption{Проверка значений метода Ньютона}
	\end{figure}

	\subsection*{Реализация на Python}
	\lstinputlisting[language=Python, caption={Python код программы}]{Polinom_Newton.py}
	
	\section{Задание 3}
	3. По заданным эксперементальным точкам выбрать вид эмпиреической зависимости и выполнить среднеквадратичное приближение функции,
\[
\begin{array}{|c|c|}
	\hline
	x_i & y_i \\ \hline
	0.1 & 1.91 \\ 
	0.2 & 3.03 \\
	0.3 & 3.98 \\ 
	0.4 & 4.82 \\
	0.5 & 5.59 \\
	0.6 & 6.31 \\
	0.7 & 7.00 \\
	0.8 & 7.65 \\
	0.9 & 8.27 \\ 
	1.0 & 8.88 \\ \hline
\end{array}
\]

	\subsection{Анализ выбора эмпирической зависимости}
	Перед построением регрессии необходимо определить тип зависимости. В вашем коде использовался следующий подход:
	
	\subsection{Расчет характерных точек}
	\begin{itemize}
		\item Среднее арифметическое:
		\[ x_{\text{ср}} = x_1 + \frac{x_n}{2} = 0.1 + \frac{1.0}{2} = 0.6 \]
		\[ y_{\text{ср}} = y_1 + \frac{y_n}{2} = 1.91 + \frac{8.88}{2} \approx 5.35 \]
		
		\item Среднее геометрическое:
		\[ x_{\text{геом}} = \sqrt{x_1 \cdot x_n} = \sqrt{0.1 \cdot 1.0} \approx 0.316 \]
		\[ y_{\text{геом}} = \sqrt{y_1 \cdot y_n} = \sqrt{1.91 \cdot 8.88} \approx 4.12 \]
		
		\item Среднее гармоническое:
		\[ x_{\text{гарм}} = \frac{2x_1 x_n}{x_1 + x_n} = \frac{2 \cdot 0.1 \cdot 1.0}{0.1 + 1.0} \approx 0.182 \]
		\[ y_{\text{гарм}} = \frac{2y_1 y_n}{y_1 + y_n} = \frac{2 \cdot 1.91 \cdot 8.88}{1.91 + 8.88} \approx 3.14 \]
	\end{itemize}
	
	\subsection{Определение ближайших экспериментальных точек}
	Для каждой характерной точки находим ближайшую экспериментальную точку:
	
	\begin{verbatim}
		Ошибки для каждой модели:
		[(0.040, 2.192, 2.533), 
		(2.370, 0.138, 0.203), 
		(2.370, 0.138, 0.203)]
	\end{verbatim}
	
	Минимальные ошибки:
	\begin{itemize}
		\item Для арифметического среднего: 0.040
		\item Для геометрического среднего: 0.138
		\item Для гармонического среднего: 0.203
	\end{itemize}
	
	
	Наименьшая ошибка (0.040) соответствует \textbf{арифметическому среднему}, что указывает на линейную зависимость.
	
	После определения типа зависимости строим линейную модель...
	
		Коэффициенты линейной регрессии:
	\[
	a \approx 7.577, \quad b \approx 1.577, \quad \sigma \approx 0.2090.
	\]
		\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{Задание3График.png}
		\caption{График линейной зависимости}}
	\end{figure}
	\subsection{проверка}
		\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\textwidth]{ПроверкаЗадание3.png}
		\caption{Проверка метода МНК}
	\end{figure}
	$\sigma^{2} = 0.4768$, значит $\sigma \approx  0.2090$. Поэтому наши вычисления сходятся с проверкой, как и сами коэффиценты.
		\subsection*{Реализация на Python}
	\lstinputlisting[language=Python, caption={Python код программы}]{MS.py}
	
	\section{Вывод}
	В ходе данной лабораторной работы, я смог ознакомлся с 4 методами интерполяции полинома. А именно: полином Лагранжа, 1 и 2 форма Ньютона и метод наименьших квадратов(МНК). Эти методы были реализованы в программес использованием высокого языка программирования (Python). Также вычесленные корни были проверены, они сошлись с минимальной погрешностью.
\end{document}


